{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Project - SAAS Career Exploration - Part 3\n",
    "\n",
    "This will be the last part of this project! Since this is a bit longer than the previous parts, it will be due in **two weeks** instead of one, so the due date will be **November 3rd**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T22:54:16.525074Z",
     "start_time": "2020-03-08T22:54:11.988544Z"
    },
    "code_folding": [
     21
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>No Preference</th>\n",
       "      <th>Uncommitted</th>\n",
       "      <th>Ben Carson</th>\n",
       "      <th>Bernie Sanders</th>\n",
       "      <th>Carly Fiorina</th>\n",
       "      <th>Chris Christie</th>\n",
       "      <th>Donald Trump</th>\n",
       "      <th>Hillary Clinton</th>\n",
       "      <th>...</th>\n",
       "      <th>Hispanic-owned firms, percent, 2007</th>\n",
       "      <th>Women-owned firms, percent, 2007</th>\n",
       "      <th>Manufacturers shipments, 2007 ($1,000)</th>\n",
       "      <th>Merchant wholesaler sales, 2007 ($1,000)</th>\n",
       "      <th>Retail sales, 2007 ($1,000)</th>\n",
       "      <th>Retail sales per capita, 2007</th>\n",
       "      <th>Accommodation and food services sales, 2007 ($1,000)</th>\n",
       "      <th>Building permits, 2014</th>\n",
       "      <th>Land area in square miles, 2010</th>\n",
       "      <th>Population per square mile, 2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>598175</td>\n",
       "      <td>12003</td>\n",
       "      <td>88157</td>\n",
       "      <td>131</td>\n",
       "      <td>594.44</td>\n",
       "      <td>91.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.647</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1410273</td>\n",
       "      <td>0</td>\n",
       "      <td>2966489</td>\n",
       "      <td>17166</td>\n",
       "      <td>436955</td>\n",
       "      <td>1384</td>\n",
       "      <td>1589.78</td>\n",
       "      <td>114.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188337</td>\n",
       "      <td>6334</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>884.88</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124707</td>\n",
       "      <td>5804</td>\n",
       "      <td>10757</td>\n",
       "      <td>19</td>\n",
       "      <td>622.58</td>\n",
       "      <td>36.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>341544</td>\n",
       "      <td>0</td>\n",
       "      <td>319700</td>\n",
       "      <td>5622</td>\n",
       "      <td>20941</td>\n",
       "      <td>3</td>\n",
       "      <td>644.78</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state   county   No Preference   Uncommitted  Ben Carson  Bernie Sanders  \\\n",
       "0  Alabama  Autauga             NaN           NaN       0.146           0.182   \n",
       "1  Alabama  Baldwin             NaN           NaN       0.084           0.329   \n",
       "2  Alabama  Barbour             NaN           NaN       0.122           0.078   \n",
       "3  Alabama     Bibb             NaN           NaN       0.099           0.197   \n",
       "4  Alabama   Blount             NaN           NaN       0.100           0.386   \n",
       "\n",
       "   Carly Fiorina  Chris Christie  Donald Trump  Hillary Clinton  \\\n",
       "0            NaN             NaN         0.445            0.800   \n",
       "1            NaN             NaN         0.469            0.647   \n",
       "2            NaN             NaN         0.501            0.906   \n",
       "3            NaN             NaN         0.494            0.755   \n",
       "4            NaN             NaN         0.487            0.551   \n",
       "\n",
       "                ...                 Hispanic-owned firms, percent, 2007  \\\n",
       "0               ...                                                 0.7   \n",
       "1               ...                                                 1.3   \n",
       "2               ...                                                 0.0   \n",
       "3               ...                                                 0.0   \n",
       "4               ...                                                 0.0   \n",
       "\n",
       "   Women-owned firms, percent, 2007  Manufacturers shipments, 2007 ($1,000)  \\\n",
       "0                              31.7                                       0   \n",
       "1                              27.3                                 1410273   \n",
       "2                              27.0                                       0   \n",
       "3                               0.0                                       0   \n",
       "4                              23.2                                  341544   \n",
       "\n",
       "   Merchant wholesaler sales, 2007 ($1,000)  Retail sales, 2007 ($1,000)  \\\n",
       "0                                         0                       598175   \n",
       "1                                         0                      2966489   \n",
       "2                                         0                       188337   \n",
       "3                                         0                       124707   \n",
       "4                                         0                       319700   \n",
       "\n",
       "   Retail sales per capita, 2007  \\\n",
       "0                          12003   \n",
       "1                          17166   \n",
       "2                           6334   \n",
       "3                           5804   \n",
       "4                           5622   \n",
       "\n",
       "   Accommodation and food services sales, 2007 ($1,000)  \\\n",
       "0                                              88157      \n",
       "1                                             436955      \n",
       "2                                                  0      \n",
       "3                                              10757      \n",
       "4                                              20941      \n",
       "\n",
       "   Building permits, 2014 Land area in square miles, 2010  \\\n",
       "0                     131                          594.44   \n",
       "1                    1384                         1589.78   \n",
       "2                       8                          884.88   \n",
       "3                      19                          622.58   \n",
       "4                       3                          644.78   \n",
       "\n",
       "  Population per square mile, 2010  \n",
       "0                             91.8  \n",
       "1                            114.6  \n",
       "2                             31.0  \n",
       "3                             36.8  \n",
       "4                             88.9  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup code\n",
    "import seaborn as sns #; sns.set()\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16,8)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "sns.set()\n",
    "\n",
    "from IPython.display import display, Latex, Markdown\n",
    "\n",
    "general = pd.read_csv(\"2016-us-election/county_facts.csv\")\n",
    "column_dict_df = pd.read_csv(\"2016-us-election/county_facts_dictionary.csv\")\n",
    "primaries = pd.read_csv(\"2016-us-election/primary_results.csv\")\n",
    "\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Palau': 'PW',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY',\n",
    "}\n",
    "# Credit to https://gist.github.com/rogerallen/1583593\n",
    "\n",
    "# Turn the county_facts_dictionary.csv file into a dictionary\n",
    "column_dict = column_dict_df.set_index(\"column_name\").to_dict()['description']\n",
    "\n",
    "# Use that dictionary to rename the columns of general\n",
    "general.columns = general.columns.to_series().map(lambda x: column_dict.get(x,x))\n",
    "\n",
    "# Extract the rows corresponding to states from general (note that these are the rows with NaN in the \n",
    "# state_abbreviation column, minus the first row which is the whole US)\n",
    "states = general[general['state_abbreviation'].isnull()][1:].reset_index(drop=True)\n",
    "\n",
    "# Attach the state abbreviations to the states dataframe\n",
    "states[\"state_abbreviation\"] = general[\"state_abbreviation\"].unique()[1:]\n",
    "\n",
    "# Extract the rows corresponding to counties from general\n",
    "counties = general[~general['state_abbreviation'].isnull()].reset_index(drop=True)\n",
    "\n",
    "# Create the pivot table from last time\n",
    "pivot_table = pd.pivot_table(primaries,index=[\"state\",\"county\"],columns=\"candidate\",values=\"fraction_votes\")\n",
    "pivot_table.reset_index(inplace = True)\n",
    "\n",
    "# Join the two dataframes together\n",
    "pivot_table[\"state_abbreviation\"] = pivot_table[\"state\"].map(us_state_abbrev)\n",
    "pivot_table[\"state_county\"] = pivot_table[\"state_abbreviation\"] + \" \" + pivot_table['county'] + ' County'\n",
    "counties[\"state_county\"] = counties[\"state_abbreviation\"] + \" \" + counties[\"area_name\"]\n",
    "\n",
    "df = pd.merge(pivot_table,counties,on=\"state_county\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear models\n",
    "\n",
    "In this last part, we are going to create linear models to predict various parts of your data. First, pick a quantititative variable $y$ which you would like to predict and another quantitative variable $x$ which you think will be predictive of $y$. \n",
    "\n",
    "### 1.1. Preliminary plotting\n",
    "\n",
    "Before we actually fit a linear model, we should make sure that there is a somewhat linear relationship between our two variables. <span style=\"color:blue\"> Plot a scatterplot of $x$ and $y$ and verify that the relationship looks somewhat linear. </span> If it looks like there is some relationship but it is nonlinear, you can try [straightening the data](https://rstudio-pubs-static.s3.amazonaws.com/199830_f5e58983719e4ffc8d60fd277f9352e5.html) by applying transformations such as $x^2$ or $\\sqrt{x}$ to the axes; alternatively, you can just try to find a different $x$ or $y$ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Next, use sklearn to fit a linear model of $y$ on $x$. </span> Remember that in order to do this, you'll need to first create variables `X` and `Y` to feed into the `linear_model.fit` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our linear model, <span style=\"color:blue\">add the line of best fit to the scatterplot from above</span>. If you want some additional practice, try doing this from scratch instead of copying the function from the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Assessing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's assess the validity of our model.<span style=\"color:blue\"> Find the $R^2$ value and write an explanation of what that value means.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR EXPLANATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,<span style=\"color:blue\"> add an additional column to your dataframe with the residuals from your linear model, and make a plot of the residuals against $x$.</span> (Recall that the $i$th residual is given by $y_i - \\hat y_i$, where $\\hat y_i$ is your predicted value for $y_i$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, this plot just looks like random noise. <span style=\"color:blue\">Does it? If not, what are the patterns you see and why do you think they appear?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR EXPLANATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. MSE Breakdown\n",
    "\n",
    "Another common metric used for evaluating linear models is the **mean squared error** or MSE. This is just the average of all the squared errors: \n",
    "$$MSE := \\frac{1}{n}\\sum_{i=1}^n \\left(y_i-\\hat y_i\\right)^2$$\n",
    "\n",
    "Note that you can compute this by taking the average of the squares of the residuals.\n",
    "\n",
    "First, find the MSE of your linear model on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to see if our model is doing better or worse on different parts of our dataset. Pick a categorical variable $z$ in the dataset that you think is related to $y$. If you don't have any categorical variables you think are relevant, then you could pick some quantitative variable (other than $x$ and $y$) and split your data up into \"categories\" based on whether or not that variable is greater than its mean - for example, doing separate regressions on counties which voted more than average or less than average for Sanders. In this case, make sure you add an indicator variable column to your dataframe - I'll refer to this column as $z$.\n",
    "\n",
    "After selecting $z$, find the MSE for each possible value of $z$, i.e. for each possible category of your data. To do this, find the average squared residual in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are some categories much better or worse than others? Why do you think this might be the case? To answer this, feel free to poke around a little bit more in your data - for example, you could try making plots of $x$ vs $y$ in each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Submission\n",
    "\n",
    "**To submit, first save this file as a pdf by going to the top left and clicking File -> Download as -> PDF via LaTex (.pdf), then fill out this form!**\n",
    "\n",
    "https://docs.google.com/forms/d/e/1FAIpQLSfjI4yuukEC60rfOYPsJ7r1W0u4Kwjpr8pVxXL1qpqXu4hq0w/viewform"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
